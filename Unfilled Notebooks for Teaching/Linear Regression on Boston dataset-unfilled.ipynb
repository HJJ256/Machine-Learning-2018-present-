{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variate Linear Regression on Boston Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code to implement multivariate linear regression on boston dataset from scratch\n",
    "\n",
    "# ===================================Importing libraries====================================\n",
    "import numpy as np                              #for handling arrays and matrices\n",
    "import pandas as pd                             #for working with datasets and dataframes\n",
    "from matplotlib import pyplot as plt            #for visualisation purposes\n",
    "from sklearn.datasets import load_boston        #importing the boston dataset from scikit-learn  \n",
    "\n",
    "from sklearn.linear_model import LinearRegression  #to compare our results with standard library results\n",
    "from sklearn.model_selection import train_test_split #to split the dataset into test and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset from sklearn\n",
    "dataset = ?()         #loading the contents of the dictionary-dataset into 'dataset'\n",
    "print(?.?())           #displaying the keys of the dictionary dataset\n",
    "\n",
    "#=====================================DATASET INFORMATION===================================\n",
    "#data-input data\n",
    "#target- results of each sample stored in the target variable\n",
    "#feature_names- attribute names/column names in the input data\n",
    "#DESCR- description of the dataset\n",
    "\n",
    "print(?['feature_names'])     #printing the names of the features\n",
    "\n",
    "print(?.?.?)           #printing the shape (dimensional size) of the input data\n",
    "print(?.?.?)         #printing the size of target variable\n",
    "print(dataset.?)                #describing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing features in x and target variable in y\n",
    "x = dataset.?\n",
    "y = dataset.?\n",
    "\n",
    "y = y.?(y.shape[0], 1)\n",
    "\n",
    "# converting into a dataframe\n",
    "df = pd.?(x)\n",
    "df.columns = dataset.?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding target variable to our dataframe\n",
    "df['PRICE'] = y\n",
    "\n",
    "# ============finding correlation between attributes and target variable===============\n",
    "print(np.corrcoef(np.transpose(df))[-1, :])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ normalising the dataset=========================\n",
    "\n",
    "df =(df - df.mean()) / df.std()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================== MULTI-VARIATE LINEAR REGRESSION ========================\n",
    "\n",
    "# ============================== INITIALISING HYPER-PARAMETERS =========================\n",
    "# Hyper-parameters for a multi-variate linear regression are: \n",
    "#  1. Theta (weights) which describe the line\n",
    "#  2. epochs- number of times we run our linear regression to minimise the loss\n",
    "#  3. alpha- the learning rate\n",
    "\n",
    "\n",
    "# initialising theta with zeros \n",
    "theta = np.?((1, x.shape[1] + 1)) #its dimensions are (1,14) because of the presence of a bias term (intercept)\n",
    "print(theta.?)\n",
    "print(theta)\n",
    "\n",
    "#Both epoch and alpha can be changed and tested on different numbers \n",
    "# to minimise loss at a different rate(Advisable)\n",
    "epoch = ?\n",
    "alpha = ? \n",
    "\n",
    "# creating bias vector x0\n",
    "x0 = np.?((x.shape[0], 1))\n",
    "\n",
    "# forming input variable\n",
    "X = np.?((x0, x), axis = 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================splitting the data into train and test===========================\n",
    "\n",
    "def train_test_splitt(dataset, ratio = 0.7):\n",
    "    m = len(df)\n",
    "    \n",
    "    #if ratio to be divided is given in percentage, multiply with 0.01\n",
    "    if ratio > 1:\n",
    "        train_ratio = int(ratio * 0.01 * m)\n",
    "    else:\n",
    "        train_ratio = int(ratio * m)\n",
    "\n",
    "    x_train = dataset[:train_ratio, :-1]\n",
    "    x_test = dataset[train_ratio: , :-1]\n",
    "    \n",
    "    y_train = dataset[:train_ratio, -1:]\n",
    "    y_test = dataset[train_ratio: , -1:]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# data = np.concatenate((X, y), axis = 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(data)\n",
    "y_train = y_train.reshape((y_train.shape[0], 1))\n",
    "y_test = y_test.reshape((y_test.shape[0], 1))\n",
    "\n",
    "print(df.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================ DEFINING COST FUNCTION ================================\n",
    "def cost_function(X, y, theta):\n",
    "    h = X.?(theta.T)\n",
    "    loss = h - y\n",
    "    return np.?(loss ** 2)/ (2 * len(X))\n",
    "\n",
    "# For testing the function\n",
    "cost = ?(x_train, y_train, theta)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ DEFINING GRADIENT DESCENT =========================\n",
    "def grad_descent(X, y, theta, alpha):\n",
    "    h = X.?(theta.T)\n",
    "    loss = ?\n",
    "    dj = (?.T).dot(X)\n",
    "    theta = theta - (alpha/len(X)) * dj\n",
    "    return theta\n",
    "\n",
    "# For testing the function \n",
    "cost = ?(x_train, y_train, theta)\n",
    "print(\"Cost before: \", cost)\n",
    "\n",
    "theta = ?(x_train, y_train, theta, 0.0000001)\n",
    "\n",
    "cost = ?(x_train, y_train, theta)\n",
    "print(\"Cost after: \", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== DEFINING OUR LINEAR REGRESSION =========================\n",
    "def linear_reg(epoch, X, y, theta, alpha):\n",
    "    ?:\n",
    "        \n",
    "        #calculate new theta\n",
    "        theta = ?(X, y, theta, alpha)\n",
    "        \n",
    "        #compute new loss\n",
    "        loss = ?(X, y, theta)\n",
    "        print(\"Cost function: \", loss)\n",
    "        \n",
    "    return theta\n",
    "\n",
    "theta = ?(epoch, x_train, y_train, theta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= TESTING THE DATA ========================\n",
    "def predict(x_test, theta):\n",
    "    return x_test.?(theta.T)\n",
    "\n",
    "y_pred =  predict(x_test, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== Find error in the predicted values=============\n",
    "def mean_squared_error(h, y):\n",
    "    m = y.shape[0]\n",
    "    return np.sum(((h - y) ** 2 ) / m)\n",
    "\n",
    "# for testing the function\n",
    "# mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= Plotting hypothesis value vs actual value for train set=========\n",
    "h = x_train.?(theta.T)\n",
    "plt.plot(h, y_train, 'b.')\n",
    "plt.ylabel('Actual value')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.show()\n",
    "\n",
    "print(?(h, y_train))\n",
    "print(?(x_train, y_train, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Plotting hypothesis value vs actual value for test set =======\n",
    "\n",
    "plt.?(y_pred, y_test, 'b.')\n",
    "plt.?('Actual value')\n",
    "plt.?('Predicted value')\n",
    "plt.show()\n",
    "\n",
    "print(?(y_pred, y_test))\n",
    "print(?(x_test, y_test, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============= COMPARING WITH SKLEARN'S LINEAR REGRESSION MODEL ===============\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.?(x_train, y_train)\n",
    "\n",
    "y_predict = lm.?(x_test)\n",
    "\n",
    "plt.?(y_predict, y_test, 'b.')\n",
    "plt.?('Actual value')\n",
    "plt.?('Predicted value')\n",
    "plt.show()\n",
    "\n",
    "print(lm.?(x_test, y_test))\n",
    "print(?(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing error acheived by our algorithm with the inbuilt library for linear regression, we see there is a difference between the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
