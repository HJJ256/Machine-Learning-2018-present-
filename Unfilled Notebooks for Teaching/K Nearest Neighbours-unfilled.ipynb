{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'k' : [[1,2],[2,3],[3,1]],\n",
    "           'r': [[6,5],[7,7],[8,6]]} #For any new dataset, We have to bring in this format for using our algorithm\n",
    "\n",
    "new_features = [3,5] #new point which needs to be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data,predict,k=3): #We define function so that we can reuse it afterwards for new dataset\n",
    "    distances = []\n",
    "    ?:#r\n",
    "        ?:\n",
    "            distance = np.?(np.array(features)-np.array(predict))\n",
    "            distances.?([distance,group])\n",
    "    votes = ?\n",
    "    vote_result = ?\n",
    "    return vote_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ?(dataset,new_features,3) #function call\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('X1') #Gives the X axis a label X1\n",
    "plt.ylabel('X2') #Gives the Y axis a label X2\n",
    "\n",
    "for group in dataset:\n",
    "    for features in dataset[group]:\n",
    "        print(features)\n",
    "        plt.?(features[0],features[1],s=100,color = group) #A single point is plotted on graph\n",
    "plt.?(new_features[0],new_features[1],s=100) #Point to be predicted is plotted on graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= {'k':[[1,2],[2,3],[3,1]],'r':[[6,5],[8,6],[7,7]]}\n",
    "new_pt = [3,4]\n",
    "k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?(dataset,new_pt,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.?('Breast-Cancer.csv') #Used to read comma seperated value file and store it in pandas dataframe\n",
    "df.?('?',-99999,inplace = True) #replacing missing values denoted by '?' with -99999 in df variable itself\n",
    "df.?(['id'],axis=1,inplace=True) #removing the column (axis = 1 means column) 'id' as it is not needed for processing\n",
    "full_data = df.?(float).?.?() #Converting dataframe into a normal list for further processing\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int(0.8*699)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.?(full_data) #We shuffle our data so that we get some uniformity in the examples used as train and test data\n",
    "#That is to say that we shouldn't have all examples of only a single class in the test data\n",
    "#TRAIN-TEST-SPLIT\n",
    "test_size = 0.2\n",
    "\n",
    "train_data = ?[:-int(test_size*len(full_data))]\n",
    "test_data = ?[-int(test_size*len(full_data)):]\n",
    "len(train_data) #each list inside main list has 10 elements i.e. 9 features and 1 label, same for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ? #We need our dataset in dictionary format so that we can use it in KNN function\n",
    "test_set = ?\n",
    "?:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "    #We took one-one list from train_data and appended the features from that list into dictionary \n",
    "    #with key as last element (label) of that list\n",
    "?:\n",
    "    test_set[i[-1]].append(i[:-1]) #same process repeated for test data\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?(train_set,[5,10,10,5,4,5,4,4,1],11) #passing a single data [5,10,10,5,4,5,4,4,1] for prediction \n",
    "#if tumor is benign (2) or malignant (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = [] #list to append accuracy in\n",
    "z = ? #list of all values of k used below\n",
    "for k in range(1,100,2):\n",
    "    correct = 0\n",
    "    total = len(test_data)\n",
    "    ?:\n",
    "        ?: #data contains a list of 9 features x1,x2...x9\n",
    "            vote = ?(train_set,data,k) #we check classification made by knn for data variable\n",
    "            if group == vote: #if group of data variable = classification made by knn then correct += 1\n",
    "                correct+=1\n",
    "    accuracy.?(correct/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy list will have some accuracy at 0th index for k =1, at 1st index for k =2 and at nth index for k = n+1\n",
    "print(max(accuracy),z[accuracy.index(max(accuracy))]) #printing maximum accuracy and first value of kfor which it occurs\n",
    "#PLOTTING ACCURACY VS. K graph for analysis of performance of KNN on breast cancer classification problem\n",
    "plt.?(\"k\")\n",
    "plt.?(\"Accuracy\")\n",
    "plt.?(z,accuracy) \n",
    "#Plot functions gives a continuous line over all points in z (list of x coordinate) and accuracy (list of y coordinate)\n",
    "plt.show() #shows the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z[accuracy.index(max(accuracy))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sum((np.array([3,3]) - np.array([3,4]))**2)**0.5 #distance formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([3,3]) - np.array([3,4])) #Distance formula using np.linalg (linear algebra class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [] #List to append distances in \n",
    "k = 3 #Value of k in KNN\n",
    "for group in dataset:#r,k\n",
    "    for features in dataset[group]: #Single datapoint from dataset is saved in features\n",
    "        distance = np.linalg.norm(np.array(new_features) - np.array(features)) #distance of new_pt from the datapoint\n",
    "        distances.append([distance,group]) #distance is appended with group so that we can classify later\n",
    "#votes = []\n",
    "#for i in sorted(distances)[:3]:\n",
    "#    votes.append(i[1])\n",
    "votes = [i[1] for i in sorted(distances)[:3]]\n",
    "print(votes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(votes).most_common(1) #remove square bracket one by one to see all outputs\n",
    "#used for finding final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in dataset:\n",
    "    for features in dataset[group]:\n",
    "        print(group,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "votes = ['r','r','k']\n",
    "Counter(votes).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS PROCESS IS CALLED TRAIN-TEST-SPLIT\n",
    "x=[1,2,3,4,5,6,7,8,9,10]\n",
    "test_size = 0.2 #20% data is used as test data\n",
    "train_data = ? #Smartly using slicing operation to create train and test data\n",
    "test_data = ?\n",
    "test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
