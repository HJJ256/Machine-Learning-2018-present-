{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, LeakyReLU,UpSampling2D,concatenate,Input\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_net():\n",
    "    input_shape = Input(shape=(None,None,3))\n",
    "    tower_1 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(input_shape))\n",
    "    tower_1 = (LeakyReLU(alpha=0.1)(tower_1))#encconv0\n",
    "\n",
    "    tower_1 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_1))\n",
    "    tower_1 = (LeakyReLU(alpha=0.1)(tower_1))#encconv1\n",
    "    tower_1 = (MaxPooling2D(pool_size=(2,2))(tower_1))#pool1\n",
    "\n",
    "    tower_2 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_1))\n",
    "    tower_2 = (LeakyReLU(alpha=0.1)(tower_2))#encconv2\n",
    "    tower_2 = (MaxPooling2D(pool_size=(2,2))(tower_2))#pool2\n",
    "\n",
    "    tower_3 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_2))\n",
    "    tower_3 = (LeakyReLU(alpha=0.1)(tower_3))#encconv3\n",
    "    tower_3 = (MaxPooling2D(pool_size=(2,2))(tower_3))#pool3\n",
    "\n",
    "    tower_4 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_3))\n",
    "    tower_4 = (LeakyReLU(alpha=0.1)(tower_4))#encconv4\n",
    "    tower_4 = (MaxPooling2D(pool_size=(2,2))(tower_4))#pool4\n",
    "\n",
    "    tower_5 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_4))\n",
    "    tower_5 = (LeakyReLU(alpha=0.1)(tower_5))#encconv5\n",
    "    tower_5 = (MaxPooling2D(pool_size=(2,2))(tower_5))#pool5\n",
    "\n",
    "    tower_6 = (Conv2D(48,kernel_size=(3,3), padding=\"same\")(tower_5))\n",
    "    tower_6 = (LeakyReLU(alpha=0.1)(tower_6))#encconv6\n",
    "    tower_6 = (UpSampling2D(size=(2,2))(tower_6))\n",
    "\n",
    "    out_1 = concatenate([tower_6,tower_4],axis=3)\n",
    "\n",
    "    tower_7 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(out_1)\n",
    "    tower_7 = LeakyReLU(alpha=0.1)(tower_7)\n",
    "    tower_7 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(tower_7)\n",
    "    tower_7 = LeakyReLU(alpha=0.1)(tower_7)\n",
    "    tower_7 = UpSampling2D(size=(2,2))(tower_7)\n",
    "\n",
    "    out_2 = concatenate([tower_7,tower_3],axis=3)\n",
    "\n",
    "    tower_8 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(out_2)\n",
    "    tower_8 = LeakyReLU(alpha=0.1)(tower_8)\n",
    "    tower_8 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(tower_8)\n",
    "    tower_8 = LeakyReLU(alpha=0.1)(tower_8)\n",
    "    tower_8 = UpSampling2D(size=(2,2))(tower_8)\n",
    "\n",
    "    out_3 = concatenate([tower_8,tower_2],axis=3)\n",
    "\n",
    "    tower_9 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(out_3)\n",
    "    tower_9 = LeakyReLU(alpha=0.1)(tower_9)\n",
    "    tower_9 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(tower_9)\n",
    "    tower_9 = LeakyReLU(alpha=0.1)(tower_9)\n",
    "    tower_9 = UpSampling2D(size=(2,2))(tower_9)\n",
    "\n",
    "    out_4 = concatenate([tower_9,tower_1],axis=3)\n",
    "\n",
    "    tower_10 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(out_4)\n",
    "    tower_10 = LeakyReLU(alpha=0.1)(tower_10)\n",
    "    tower_10 = Conv2D(96,kernel_size=(3,3),padding=\"same\")(tower_10)\n",
    "    tower_10 = LeakyReLU(alpha=0.1)(tower_10)\n",
    "    tower_10 = UpSampling2D(size=(2,2))(tower_10)\n",
    "\n",
    "    out_4 = concatenate([tower_10,input_shape],axis=3)\n",
    "\n",
    "    tower_11 = Conv2D(64,kernel_size=(3,3),padding=\"same\")(out_4)\n",
    "    tower_11 = LeakyReLU(alpha=0.1)(tower_11)\n",
    "    tower_11 = Conv2D(32,kernel_size=(3,3),padding=\"same\")(tower_11)\n",
    "    tower_11 = LeakyReLU(alpha=0.1)(tower_11)\n",
    "    final_out = Conv2D(3,kernel_size=(3,3),padding=\"same\",activation=\"linear\")(tower_11)\n",
    "\n",
    "    model = Model(input_shape, final_out)\n",
    "    plot_model(model,to_file=\"Nvidia Network.png\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = creat_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros(shape=(375,500,3))\n",
    "i = 0\n",
    "for filename in glob.glob('N2N/train/*.JPEG'):\n",
    "    im=Image.open(filename)\n",
    "    if(im.size!=(500,375)):\n",
    "        if(im.size[1]>im.size[0]):\n",
    "            im = im.rotate(90)\n",
    "        im = im.resize((500,375))\n",
    "        #im=im.reshape((3,im.shape[0]*im.shape[1]))\n",
    "    if(len(np.array(im).shape) == 3 and np.array(im).shape[2]==3):\n",
    "        train_data = np.concatenate((train_data,np.array(im)),axis=0)\n",
    "    i+=1\n",
    "    if i%1000==0:\n",
    "        print(i,\" images done\")\n",
    "    if i==500:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[138., 135., 128.],\n",
       "        [157., 154., 147.],\n",
       "        [159., 156., 149.],\n",
       "        ...,\n",
       "        [176., 175., 171.],\n",
       "        [183., 180., 173.],\n",
       "        [136., 132., 123.]],\n",
       "\n",
       "       [[157., 152., 146.],\n",
       "        [175., 172., 165.],\n",
       "        [160., 157., 150.],\n",
       "        ...,\n",
       "        [106., 103.,  98.],\n",
       "        [113., 108., 102.],\n",
       "        [143., 136., 128.]],\n",
       "\n",
       "       [[141., 134., 128.],\n",
       "        [161., 156., 150.],\n",
       "        [161., 161., 153.],\n",
       "        ...,\n",
       "        [142., 137., 131.],\n",
       "        [150., 143., 135.],\n",
       "        [136., 129., 121.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape((491,375,500,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"MSE\",optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data[1:],train_data[1:],batch_size=200,epochs = 10 ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
