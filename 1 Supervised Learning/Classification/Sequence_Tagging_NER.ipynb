{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Tagging NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLW2VjQ-fWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPNYwfVu82yx",
        "colab_type": "code",
        "outputId": "39ab2291-6165-49d9-fe6a-cdb80463df3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "A = np.random.randn(4,3)\n",
        "B = np.sum(A, axis = 1, keepdims = True)\n",
        "B.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrcK9EOkdvha",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EwaLWlmn_ov",
        "colab_type": "code",
        "outputId": "28697410-06d0-4da7-85e6-a7a014b744dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.drop(['POS'], axis =1)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word Tag\n",
              "0  Sentence: 1      Thousands   O\n",
              "1          NaN             of   O\n",
              "2          NaN  demonstrators   O\n",
              "3          NaN           have   O\n",
              "4          NaN        marched   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-KjRO9E-sl2",
        "colab_type": "code",
        "outputId": "89bf2377-cfc6-4faf-c1f8-e8a0097ed0d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.drop(['POS'], axis =1)\n",
        "data = data.fillna(method=\"ffill\")\n",
        "words = set(list(data['Word'].values)) #Vocabulary\n",
        "words.add('PADword')\n",
        "n_words = len(words)\n",
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "print(n_words,n_tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35179 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_PIxrMLd0Nj",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC36wSmu-5OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "  def __init__(self, data):\n",
        "      self.n_sent = 1\n",
        "      self.data = data\n",
        "      self.empty = False\n",
        "      agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].\n",
        "                                                   values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "      self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "      self.sentences = [s for s in self.grouped]\n",
        "\n",
        "  def get_next(self):\n",
        "      try:\n",
        "          s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "          self.n_sent += 1\n",
        "          return s\n",
        "      except:\n",
        "          return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkEXqoyQ-5R2",
        "colab_type": "code",
        "outputId": "8ad1cab9-093c-46c3-8371-f314133d3e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "getter = SentenceGetter(data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LzWI1cPq_mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent = getter.get_next()\n",
        "print(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZYueXXK-5U-",
        "colab_type": "code",
        "outputId": "132f86a7-ea6c-471a-82df-08c826b6b490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = getter.sentences\n",
        "print(len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLoo_EID-5Xu",
        "colab_type": "code",
        "outputId": "506244bf-cc8f-4972-8a63-b66ebb54a075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "largest_sen = max(len(sen) for sen in sentences)\n",
        "print('biggest sentence has {} words'.format(largest_sen))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biggest sentence has 104 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu_e02X9-5Z-",
        "colab_type": "code",
        "outputId": "fa33d9b6-4166-4b99-fbe3-39e4081ad13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "%matplotlib inline\n",
        "plt.hist([len(sen) for sen in sentences],bins=50)\n",
        "plt.xlabel('Sentence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEJCAYAAACDscAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqmLgkCRVMXBIkqoYOCRJVQwckqQq/x8Et5WQwT0fUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxHFsmR8_WWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 50\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)\n",
        "print(new_X[0])\n",
        "sentences[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU30YQlUzH2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(enumerate(tags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zGXAwa00Xph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBPDE8UO0XtF",
        "colab_type": "code",
        "outputId": "d3784f95-1c93-4cb8-9448-3aef93676f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "tags2index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art': 0,\n",
              " 'B-eve': 13,\n",
              " 'B-geo': 16,\n",
              " 'B-gpe': 8,\n",
              " 'B-nat': 5,\n",
              " 'B-org': 6,\n",
              " 'B-per': 14,\n",
              " 'B-tim': 7,\n",
              " 'I-art': 15,\n",
              " 'I-eve': 10,\n",
              " 'I-geo': 3,\n",
              " 'I-gpe': 2,\n",
              " 'I-nat': 11,\n",
              " 'I-org': 12,\n",
              " 'I-per': 9,\n",
              " 'I-tim': 4,\n",
              " 'O': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRTmq7uV_W5l",
        "colab_type": "code",
        "outputId": "27fa30a5-2e68-4ab2-8554-b41c38b8141a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  1,  1, ...,  1,  1,  1],\n",
              "       [ 8,  1,  1, ...,  1,  1,  1],\n",
              "       [ 1,  1,  7, ...,  1,  1,  1],\n",
              "       ...,\n",
              "       [ 1, 16,  1, ...,  1,  1,  1],\n",
              "       [ 1,  1,  1, ...,  1,  1,  1],\n",
              "       [ 1,  6, 12, ...,  1,  1,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpsqnPb7eDIL",
        "colab_type": "text"
      },
      "source": [
        "# Model Building and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY7J6Q5U_ZUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2018)\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TSSQyeB_dQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x,\n",
        "                                                           tf.string)),\"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                     },signature=\"tokens\",as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Hd7QUK2HT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTF43QlA_lou",
        "colab_type": "code",
        "outputId": "bdebcca2-258b-438a-c0e9-b531cb8d2157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        }
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers.merge import add\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 50, 1024)     0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 50, 1024)     6295552     lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 50, 1024)     6295552     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 50, 1024)     0           bidirectional_1[0][0]            \n",
            "                                                                 bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 50, 17)       17425       add_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 12,608,529\n",
            "Trainable params: 12,608,529\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l0FNl0DAHAP",
        "colab_type": "code",
        "outputId": "a6a960e1-985b-4f3f-87ec-ce277915a67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n",
        "y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)\n",
        "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),batch_size=batch_size, epochs=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 38816 samples, validate on 4320 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "38816/38816 [==============================] - 684s 18ms/step - loss: 0.0618 - acc: 0.9819 - val_loss: 0.0452 - val_acc: 0.9856\n",
            "Epoch 2/3\n",
            "38816/38816 [==============================] - 661s 17ms/step - loss: 0.0406 - acc: 0.9868 - val_loss: 0.0421 - val_acc: 0.9864\n",
            "Epoch 3/3\n",
            "38816/38816 [==============================] - 653s 17ms/step - loss: 0.0338 - acc: 0.9886 - val_loss: 0.0416 - val_acc: 0.9866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsFkZFB-Gd44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('bilstm_model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh4UQZ-hHkt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFkv97aEeKS7",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfC0fQU2AdWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "X_te = X_te[:149*batch_size]\n",
        "test_pred = model.predict(np.array(X_te), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGaChGrrAtWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(y_te[:149*32])\n",
        "print(classification_report(test_labels, pred_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDo9QvgA0pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 390\n",
        "p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "print(\"=\"*30)\n",
        "for w, true, pred in zip(X_te[i], y_te[i], p):\n",
        "    if w != \"__PAD__\":\n",
        "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl661oIHIJ0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bteX49ryH24U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?(figsize=(12,12))\n",
        "?(history.history[\"acc\"],c = 'b')\n",
        "?(history.history[\"val_acc\"], c = 'g')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muDt1fVVP4i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = [[\"Hawking\", \"is\", \"a\", \"Fellow\", \"of\", \"the\", \"Royal\", \"Society\", \",\", \"a\", \"lifetime\", \"member\",\n",
        "                 \"of\", \"the\", \"Pontifical\", \"Academy\", \"of\", \"Sciences\", \",\", \"and\", \"a\", \"recipient\", \"of\",\n",
        "                 \"the\", \"Presidential\", \"Medal\", \"of\", \"Freedom\", \",\", \"the\", \"highest\", \"civilian\", \"award\",\n",
        "                 \"in\", \"the\", \"United\", \"States\", \".\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXcW7hzGP5wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 50\n",
        "X_test = [[w for w in s] for s in test_sentence]\n",
        "new_X_test = []\n",
        "for seq in X_test:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X_test.append(new_seq)\n",
        "new_X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJPd5tZqSoce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(new_X_test,dtype='<U26')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b9-loz0Uv43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(X_te)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-V6UhDedqcr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GauuPDpP5zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_weights('bilstm_model.hdf5')\n",
        "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "p = ?(np.array(new_X_test*32,dtype='<U26'))[0]\n",
        "p = ?(p, axis=-1)\n",
        "print(\"{:15} {:5}\".format(\"Word\", \"Pred\"))\n",
        "print(\"=\"*30)\n",
        "for w, pred in zip(new_X_test[0], p):\n",
        "    if w != \"__PAD__\":\n",
        "        print(\"{:15}:{:5}\".format(w, tags[pred]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}