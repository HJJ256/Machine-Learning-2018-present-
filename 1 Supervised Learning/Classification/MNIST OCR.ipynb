{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = mnist.load_data() #Loading handwritten digits dataset with 28x28 images (labelled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train #Splitting data into images and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAFE1JREFUeJzt3X+sVOWdx/H3B0prAyaFovYWUSihibZpAalLgt3QmHapbYKmtdE/LNsYL39At6bGlJI0GpMmxvhja7Y1ew1ETGjVRF0JISglbl3TagVDBbzVgmXhlluQxRRMf1jku3/MubsDM3Nm7syZH8/czyuZMPM858fjIXx8znOec44iAjOzVE3qdgPMzFrhEDOzpDnEzCxpDjEzS5pDzMyS5hAzs6Q5xMwsaQ4xM0uaQ8zMkvaBTu5Mkm8PMGuziFAr6y9fvjyOHz/e0LK7du16NiKWt7K/lkVE0x9gOfAGsB9Y28Dy4Y8//rT308q/6YjgiiuuiEYBO+v8m58NPA8MA/uA72TldwJ/AHZnn2vK1vk+pUx5A/ineu1tuicmaTLwY+CLwAjwiqTNEfF6s9s0s95Q4D3Vp4HbIuJVSecDuyRtz+oeiIh7yxeWdDlwA/Ap4OPAzyV9MiLer7WDVsbErgT2R8RbEfEe8BiwooXtmVmPOHPmTEOfeiJiNCJezb6fotQjm5WzygrgsYj4W0T8nlKP7Mq8fbQSYrOAw2W/R6o1TtKgpJ2SdrawLzPrkHEOKTVM0hxgIfByVrRG0muSNkianpU1lCvlWgmxaoOHFf9VETEUEYsjYnEL+zKzDhpHiM0c66Rkn8Fq25M0DXgSuDUiTgIPAfOABcAocN/YotWak9fWVq5OjlAatBtzMXCkhe2ZWY8YRy/reL0OiqQplAJsU0Q8lW3/aFn9w8CW7Oe4c6WVntgrwHxJcyV9kNJg3OYWtmdmPaKo00lJAtYDwxFxf1n5QNli1wF7s++bgRskfUjSXGA+8Ou8fTTdE4uI05LWAM8Ck4ENEbGv2e2ZWe8o8OrkUuAmYI+k3VnZOuBGSQsonSoeBFZl+90n6QngdUpXNlfnXZkEUIGNrcuTXc3aL1qc7Lpo0aJ48cUXG1p26tSpu7o93t3RGftmloZOdm5a5RAzswoOMTNLmkPMzJLVzETWbnKImVmFRm4p6hUOMTOr4J6YmSXLp5NmljyHmJklzSFmZklziJlZsiLCVyfNLG3uiZlZ0hxiZpY0h5iZJc0hZmbJ8sC+mSXPPTEzS5pDzMyS5hAzs2T5BnAzS55DzMyS5quTZpY098TMLFkeEzOz5DnEzCxpDjEzS5pDzMyS5XsnzSx5E6YnJukgcAp4HzgdEYuLaJSZddeECbHMFyLieAHbMbMeMdFCzMz6zEQKsQCekxTAv0fEUAFtMrMummgD+0sj4oikC4Htkn4bES+ULyBpEBhscT9m1kEp9cQmtbJyRBzJ/jwGPA1cWWWZoYhY7EF/s3SM3XpU71OPpNmSnpc0LGmfpO9k5TMkbZf0u+zP6Vm5JD0oab+k1yQtqrePpkNM0lRJ5499B74E7G12e2bWO4oKMeA0cFtEXAYsAVZLuhxYC+yIiPnAjuw3wJeB+dlnEHio3g5aOZ28CHha0th2fhoR21rYnpn1gCJvAI+IUWA0+35K0jAwC1gBLMsW2wj8J/C9rPzRKDXgJUkfkTSQbaeqpkMsIt4CPtvs+mbWu8YRYjMl7Sz7PVTrAp+kOcBC4GXgorFgiojRbFwdSgF3uGy1kays+BAzs/41jquTxxsZ75Y0DXgSuDUiTmZncFUXrVKWm6gtDeybWX8qcEwMSVMoBdimiHgqKz4qaSCrHwCOZeUjwOyy1S8GjuRt3yFmZmdpNMAavDopYD0wHBH3l1VtBlZm31cCz5SVfzO7SrkE+FPeeBj4dNLMqihwnthS4CZgj6TdWdk64G7gCUk3A4eA67O6rcA1wH7gz8C36u3AIWZmFQq8Ovki1ce5AK6usnwAq8ezD4eYmVVIaca+Q6xBX//612vW3XLLLbnrHjmSOy7JX//619z6TZs25db/8Y9/rFm3f//+3HXNzjXR7p00sz7knpiZJc0hZmZJc4iZWdIcYmaWLA/sm1ny3BMzs6Q5xPrQPffcU7Nuzpw5bd33qlWrcutPnTpVs27fvn1FNycZIyMjNevy/j4Bdu7cmVvf7xxiZpasIh+K2AkOMTOr4BAzs6T56qSZJc09MTNLlsfEzCx5DjEzS5pDrA/lPTPsM5/5TO66w8PDufWXXXZZbv2iRfkvQV62bFnNuiVLluSue/jw4dz62bNn59a34vTp07n1b7/9dm79wMBA0/s+dOhQbr3niTnEzCxRvnfSzJLnnpiZJc0hZmZJc4iZWdIcYmaWLA/sm1ny+qonJmkD8FXgWER8OiubATwOzAEOAt+IiHfa18zu27FjR1N1jdi2bVtL60+fPr1m3YIFC3LX3bVrV2795z73uaba1Ih679t88803c+vrzb+bMWNGzboDBw7krjvRpRRikxpY5hFg+Tlla4EdETEf2JH9NrM+MXb/ZL1PL6gbYhHxAnDinOIVwMbs+0bg2oLbZWZd0miA9UqINTsmdlFEjAJExKikCwtsk5l1Wa8EVCPaPrAvaRAYbPd+zKw4E+Hq5FFJA1kvbAA4VmvBiBgChgAkpRPvZhNUL50qNqKRgf1qNgMrs+8rgWeKaY6Z9YK+GhOT9DNgGTBT0ghwB3A38ISkm4FDwPXtbKSZdVavBFQj6oZYRNxYo+rqgttiTXrnndpT9J5//vmWtt3qHLhWfO1rX8utz5sfB7Bnz56adY8//nhTbZooigqxGvNM7wRuAcYeGLcuIrZmdd8HbgbeB/4lIp6ttw/P2DezsxR829EjwL8Bj55T/kBE3FteIOly4AbgU8DHgZ9L+mREvJ+3g2bHxMysjxU1JlZjnmktK4DHIuJvEfF7YD9wZb2VHGJmVqEDA/trJL0maYOksXGBWUD589JHsrJcDjEzqzCOEJspaWfZp5E5oQ8B84AFwChwX1auak2ptzGPiZlZhXH0so5HxOJxbvvo2HdJDwNbsp8jQPmbaS4GjtTbnntiZnaWdt87mU2QH3MdsDf7vhm4QdKHJM0F5gO/rrc998Ssay68MP+W25/85Ce59ZMm5f8/+K677qpZd+JEo2PNE1NRVydrzDNdJmkBpVPFg8AqgIjYJ+kJ4HXgNLC63pVJcIiZWRVFzROrMc90fc7yPwR+OJ59OMTMrEJfzdg3s4mll+6LbIRDzMwqOMTMLGkOMTNL2kR4KKKZ9SmPiZk1aPXq1bn1F1xwQW593iOIAN54441xt8lKHGJmljSHmJklzSFmZskq+KGIbecQM7MK7omZWdIcYmaWNIeYmSXNIWaWWbp0ac26tWvXtrTta6+9Nrd+7969ufVWnSe7mlnyfHXSzJLmnpiZJc0hZmbJ8piYmSXPIWZmSXOImVnS+urqpKQNwFeBYxHx6azsTuAW4O1ssXURsbVdjbR0XXPNNTXrpkyZkrvujh07cut/9atfNdUmy5famFgjbwB/BFhepfyBiFiQfRxgZn2knW8AL1rdnlhEvCBpTvubYma9olcCqhGN9MRqWSPpNUkbJE0vrEVm1nUp9cSaDbGHgHnAAmAUuK/WgpIGJe2UtLPJfZlZB409FLGRTy9o6upkRBwd+y7pYWBLzrJDwFC2bG9Et5nl6pVeViOa6olJGij7eR3gxwWY9ZGUTicbmWLxM2AZMFPSCHAHsEzSAiCAg8CqNrbRzDqsVwKqEY1cnbyxSvH6NrTFEvThD384t3758mqzc0ree++93HXvuOOO3Pq///3vufXWvL4KMTObWHrpVLERDjEzq9ArVx4b4RAzswop9cRamexqZn2qqKuT2WT4Y5L2lpXNkLRd0u+yP6dn5ZL0oKT92UT6RY201SFmZmdpNMAa7K09QuW912uBHRExH9iR/Qb4MjA/+wxSmlRfl0PMzCoUFWIR8QJw4pziFcDG7PtG4Nqy8kej5CXgI+fMSa3KY2LWkttvvz23fuHChTXrtm3blrvuL3/5y6baZK1r85jYRRExmu1nVNKFWfks4HDZciNZ2WjexhxiZlZhHFcnZ55zX/RQdqthM1SlrG6aOsTM7CzjnCd2PCIWj3MXRyUNZL2wAeBYVj4CzC5b7mLgSL2NeUzMzCq0+d7JzcDK7PtK4Jmy8m9mVymXAH8aO+3M456YmVUoakysxr3XdwNPSLoZOARcny2+FbgG2A/8GfhWI/twiJlZhaJCrMa91wBXV1k2gNXj3YdDzMzOMvZQxFQ4xMysQkq3HTnELNdXvvKV3Pof/OAHufUnT56sWXfXXXc11SZrP4eYmSXNIWZmSXOImVmy/FBEM0uer06aWdLcEzOzpDnEzCxZHhOzpHz0ox/NrX/wwQdz6ydPnpxbv3Xr1pp1L730Uu661j0OMTNLmgf2zSxZPp00s+Q5xMwsaQ4xM0uaQ8zMkuYQM7Nk9d1DESXNBh4FPgacofRKph9JmgE8DswBDgLfiIh32tdUa0a9eVz13v04d+7c3PoDBw7k1td73pj1ppR6Yo287eg0cFtEXAYsAVZLupzaryI3s8S1+W1HhaobYhExGhGvZt9PAcOU3spb61XkZpa4lEJsXGNikuYAC4GXqf0qcjNLWC8FVCMaDjFJ04AngVsj4qRU7Y3jVdcbBAaba56ZdUPfhZikKZQCbFNEPJUV13oV+VkiYggYyraTzpExm8BSujpZd0xMpS7XemA4Iu4vq6r1KnIzS1y/jYktBW4C9kjanZWto/aryK2HzJs3L7f+iiuuaGn73/3ud3Pr603BsN7TSwHViLohFhEvArUGwCpeRW5m6eurEDOzicchZmZJS2lg3yFmZmfpuzExM5t4HGJmljSHmJklzSFmHXXppZfWrHvuueda2vbtt9+eW79ly5aWtm+9ySFmZskq+qGIkg4Cp4D3gdMRsbjI5xE28jwxM5tg2nDb0RciYkFELM5+F/Y8QoeYmVXowL2ThT2P0CFmZhXGEWIzJe0s+1R77FYAz0naVVZ/1vMIgaafR+gxMTM7yzh7WcfLThFrWRoRR7IHp26X9NvWWng298TMrEKRp5MRcST78xjwNHAl2fMIAfKeR9gIh5iZVThz5kxDn3okTZV0/th34EvAXgp8HqFPJ/vA4GDtp39fcsklLW37F7/4RW59SvOJrHEF/r1eBDydPc7+A8BPI2KbpFco6HmEDjEzO0uRN4BHxFvAZ6uU/w8FPY/QIWZmFVLqYTvEzKyCQ8zMkuaHIppZsvxQRDNLnkPMzJLmELNCXXXVVbn13/72tzvUEpsoHGJmljSHmJklq+iHIrabQ8zMKrgnZmZJc4iZWdIcYmaWLE92NbPk9VWISZoNPAp8DDgDDEXEjyTdCdwCvJ0tui4itraroRPZ5z//+dz6adOmNb3tAwcO5Na/++67TW/b0tVvVydPA7dFxKvZExp3Sdqe1T0QEfe2r3lm1g191RPL3kQy9laSU5KGgVntbpiZdUdqY2Ljesa+pDnAQuDlrGiNpNckbZA0vcY6g2Ovc2qppWbWMR1472RhGg4xSdOAJ4FbI+Ik8BAwD1hAqad2X7X1ImIoIhY38FonM+sRKYVYQ1cnJU2hFGCbIuIpgIg4Wlb/MLClLS00s45LaWC/bk9MpdeUrAeGI+L+svKBssWuo/QaJjNLXKO9sJR6YkuBm4A9knZnZeuAGyUtoPSK8oPAqra00Frym9/8Jrf+6qvzXzhz4sSJIptjieiVgGpEI1cnXwRUpcpzwsz6VF+FmJlNPA4xM0uaQ8zMkuWHIppZ8twTM7OkOcTMLGkphZg62VhJ6RwZs0RFRLUpUQ2bNGlSnHfeeQ0t+5e//GVXt28pdE/MzCqk1BNziJlZBV+dNLOkpdQTG9fzxMys/xV9A7ik5ZLekLRf0tqi2+sQM7MKRYWYpMnAj4EvA5dTenDE5UW21SFmZhUK7IldCeyPiLci4j3gMWBFkW31mJiZVShwYH8WcLjs9wjwD0VtHDofYseB/y77PTMr60W92rZebRe4bc0qsm2XFrCNZym1qRHnnfP+jKGIGCr7XW3OWqFXDToaYhFxQflvSTu7PVGull5tW6+2C9y2ZvVa2yJieYGbGwFml/2+GDhS4PY9JmZmbfUKMF/SXEkfBG4ANhe5A4+JmVnbRMRpSWsonaJOBjZExL4i99HtEBuqv0jX9GrberVd4LY1q5fb1rKI2EobH2ff0RvAzcyK5jExM0taV0Ks3bchtELSQUl7JO0+59JxN9qyQdIxSXvLymZI2i7pd9mf03uobXdK+kN27HZLuqZLbZst6XlJw5L2SfpOVt7VY5fTrp44bqnq+OlkdhvCm8AXKV1+fQW4MSJe72hDapB0EFgcEV2fUyTpH4F3gUcj4tNZ2T3AiYi4O/sfwPSI+F6PtO1O4N2IuLfT7TmnbQPAQES8Kul8YBdwLfDPdPHY5bTrG/TAcUtVN3pibb8NoV9ExAvAuW+vXQFszL5vpPSPoONqtK0nRMRoRLyafT8FDFOaOd7VY5fTLmtBN0Ks2m0IvfQXGcBzknZJGux2Y6q4KCJGofSPAriwy+051xpJr2Wnm1051S0naQ6wEHiZHjp257QLeuy4paQbIdb22xBatDQiFlG66351dtpkjXkImAcsAEaB+7rZGEnTgCeBWyPiZDfbUq5Ku3rquKWmGyHW9tsQWhERR7I/jwFPUzr97SVHs7GVsTGWY11uz/+JiKMR8X5EnAEepovHTtIUSkGxKSKeyoq7fuyqtauXjluKuhFibb8NoVmSpmYDrkiaCnwJ2Ju/VsdtBlZm31cCz3SxLWcZC4jMdXTp2EkSsB4Yjoj7y6q6euxqtatXjluqujLZNbuE/K/8/20IP+x4I6qQ9AlKvS8o3c3w0262TdLPgGWUnihwFLgD+A/gCeAS4BBwfUR0fIC9RtuWUTolCuAgsGpsDKrDbbsK+C9gDzD2TJl1lMafunbsctp1Iz1w3FLlGftmljTP2DezpDnEzCxpDjEzS5pDzMyS5hAzs6Q5xMwsaQ4xM0uaQ8zMkva/kXtoGgNhuAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #Displaying the image using plotting library\n",
    "plt.imshow(X_test[0],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data to bring in range 0 to 1 from 0 to 255\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1]*X_train.shape[2])\n",
    "X_test =  X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Flattened the images from 28x28 to 784 to feed to neural network neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers and activations\n",
    "model = Sequential() #Making a feed-forward artificial neural network with sequential layers\n",
    "model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 109,946\n",
      "Trainable params: 109,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n",
    "                                        #'categorical_crossentropy'])\n",
    "#Categorical crossentropy is used to define error for multiple classes (0 to 9 in this case)\n",
    "#Adam optimizer uses a combination of RMSProp and Gradient Descent Optimization technique\n",
    "#We are judging the model on its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 1.3252 - acc: 0.5253 - val_loss: 0.6177 - val_acc: 0.8422\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.4282 - acc: 0.8889 - val_loss: 0.2813 - val_acc: 0.9238\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2533 - acc: 0.9302 - val_loss: 0.2085 - val_acc: 0.9422\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.1912 - acc: 0.9463 - val_loss: 0.1742 - val_acc: 0.9513\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.1542 - acc: 0.9563 - val_loss: 0.1501 - val_acc: 0.9577\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.1288 - acc: 0.9625 - val_loss: 0.1389 - val_acc: 0.9603\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1130 - acc: 0.9674 - val_loss: 0.1280 - val_acc: 0.9635\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0980 - acc: 0.9706 - val_loss: 0.1304 - val_acc: 0.9628\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0869 - acc: 0.9756 - val_loss: 0.1177 - val_acc: 0.9644\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0744 - acc: 0.9785 - val_loss: 0.1103 - val_acc: 0.9681\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0659 - acc: 0.9813 - val_loss: 0.1046 - val_acc: 0.9686\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0596 - acc: 0.9836 - val_loss: 0.1033 - val_acc: 0.9690\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0542 - acc: 0.9848 - val_loss: 0.1053 - val_acc: 0.9686\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0489 - acc: 0.9867 - val_loss: 0.1014 - val_acc: 0.9692\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0427 - acc: 0.9887 - val_loss: 0.1006 - val_acc: 0.9705\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0389 - acc: 0.9897 - val_loss: 0.1058 - val_acc: 0.9711\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0361 - acc: 0.9905 - val_loss: 0.0998 - val_acc: 0.9718\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0310 - acc: 0.9924 - val_loss: 0.1005 - val_acc: 0.9712\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0282 - acc: 0.9936 - val_loss: 0.0995 - val_acc: 0.9731\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0258 - acc: 0.9939 - val_loss: 0.1016 - val_acc: 0.9722\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0243 - acc: 0.9941 - val_loss: 0.1009 - val_acc: 0.9723\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0215 - acc: 0.9952 - val_loss: 0.1013 - val_acc: 0.9727\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0182 - acc: 0.9963 - val_loss: 0.1023 - val_acc: 0.9728\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0169 - acc: 0.9964 - val_loss: 0.1032 - val_acc: 0.9722\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0149 - acc: 0.9970 - val_loss: 0.1088 - val_acc: 0.9712\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0143 - acc: 0.9973 - val_loss: 0.1070 - val_acc: 0.9730\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0120 - acc: 0.9980 - val_loss: 0.1040 - val_acc: 0.9741\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0104 - acc: 0.9986 - val_loss: 0.1064 - val_acc: 0.9738\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0094 - acc: 0.9986 - val_loss: 0.1093 - val_acc: 0.9722\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0084 - acc: 0.9988 - val_loss: 0.1077 - val_acc: 0.9734\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0072 - acc: 0.9992 - val_loss: 0.1098 - val_acc: 0.9739\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0066 - acc: 0.9993 - val_loss: 0.1117 - val_acc: 0.9731\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.1129 - val_acc: 0.9737\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0052 - acc: 0.9995 - val_loss: 0.1112 - val_acc: 0.9742\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0045 - acc: 0.9996 - val_loss: 0.1136 - val_acc: 0.9733\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0041 - acc: 0.9998 - val_loss: 0.1144 - val_acc: 0.9733\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.0037 - acc: 0.9998 - val_loss: 0.1154 - val_acc: 0.9738\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.1164 - val_acc: 0.9734\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0030 - acc: 0.9999 - val_loss: 0.1176 - val_acc: 0.9743\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0028 - acc: 0.9999 - val_loss: 0.1197 - val_acc: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1708afa0a58>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model using the training data\n",
    "model.fit(X_train,Y_train,batch_size=1000,\n",
    "          epochs=40,validation_split=0.2)\n",
    "#All the above parameters in fit function are hyperparameters, change them and experiment with them to see what different results can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating test accuracy\n",
    "import numpy as np\n",
    "total = len(X_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "corr=0\n",
    "for i in range(len(X_test)):\n",
    "    if np.argmax(Y_pred[i]) == np.argmax(Y_test[i]):\n",
    "        corr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.5751861e-12 4.7174291e-09 9.3421767e-07 2.4554733e-05 4.2259760e-16\n",
      " 2.1630954e-12 2.5344562e-21 9.9997425e-01 3.3572153e-08 2.4189265e-07]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working of argmax\n",
    "np.argmax(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
